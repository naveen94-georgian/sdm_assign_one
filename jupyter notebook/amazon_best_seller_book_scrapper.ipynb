{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from PIL import Image\n",
    "import os\n",
    "import tempfile\n",
    "from pymongo import MongoClient\n",
    "import gridfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a temporary folder in tempdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a folder in the tempdir to temporarily store the image data scraped from the amazon.ca website.\n",
    "\"\"\"\n",
    "temp_path = tempfile.gettempdir()+'\\\\amazon_scrapper'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.makedirs(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a connection to mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operationTime': Timestamp(1611687272, 1),\n",
       " 'ok': 0.0,\n",
       " 'errmsg': 'ns not found',\n",
       " 'code': 26,\n",
       " 'codeName': 'NamespaceNotFound',\n",
       " '$clusterTime': {'clusterTime': Timestamp(1611687272, 1),\n",
       "  'signature': {'hash': b'\\xfc\\xe8\\x9d\\xe4\\x14\\xda3%\\xdcc\\x88\\xf0\\x84\\xdb\\xdf\\xe7\\xc6\\xf8h4',\n",
       "   'keyId': 6898742217918119939}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating a connection to mongodb cluster and deleting any already existing data in the database.\n",
    "\"\"\"\n",
    "CONN_STR = 'mongodb+srv://navdb:nav123@cluster0.dnpkj.mongodb.net/?retryWrites=true&w=majority'\n",
    "client = MongoClient(CONN_STR)\n",
    "client['smd_amazon_db'].drop_collection('smd_amazon_col')\n",
    "client['smd_amazon_img_db'].drop_collection('fs.chunks')\n",
    "client['smd_amazon_img_db'].drop_collection('fs.files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = fs.find({\"filename\":\"book_1.jpg\"}).next().read()\n",
    "# with open('book_1.jpg','wb') as op:\n",
    "#     op.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data from amazon.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.amazon.ca/Best-Sellers-Books/zgbs/books/ref=zg_bs_pg_2?_encoding=UTF8&pg={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(img_src, book_rank):\n",
    "    \"\"\"\n",
    "    This method stores the image data scraped from the amazon.ca website in a mongodb database named 'smd_amazon_img_db'.\n",
    "    \"\"\"\n",
    "    img_db = client['smd_amazon_img_db']\n",
    "    fs = gridfs.GridFS(img_db)\n",
    "    img_name = 'book_'+ book_rank + '.jpg'\n",
    "    img = Image.open(requests.get(img_src, stream=True).raw)\n",
    "    img.save(temp_path+'\\\\'+img_name)\n",
    "    with open(temp_path+'\\\\'+img_name, 'rb') as img_data:\n",
    "        fs.put(img_data, content_type=img.get_format_mimetype(),filename=img_name)\n",
    "    return img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_list(page_source, book_list = [], rank= 1):\n",
    "    \"\"\"\n",
    "    The get_book_list method uses BeautifulSoup to scrape the data about bestselling books on amazon.ca and returns \n",
    "    the book_list containing the list of bestselling books on amazon\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    olist = soup.find_all('ol', {'id': 'zg-ordered-list'})[0]\n",
    "    list_items = olist.find_all('li', {'class': 'zg-item-immersion'})\n",
    "    for item in list_items:\n",
    "        book = {}\n",
    "        book['rank'] = rank\n",
    "        block = item.find_all('span', {'class': 'aok-inline-block zg-item'})[0]\n",
    "        title = block.find_all('div', {'class': 'p13n-sc-truncate-desktop-type2 p13n-sc-truncated'})[0]\n",
    "        book['title'] = title.text\n",
    "        rows = block.find_all('div', {'class': 'a-row'})\n",
    "        book['author'] = rows[0].contents[0].text\n",
    "        book['format'] = rows[1].contents[0].text\n",
    "        book['price'] = block.find_all('span', {'class': 'p13n-sc-price'})[0].text\n",
    "        icon_rows = block.find_all('div', {'class': 'a-icon-row'})\n",
    "        for ir in icon_rows:\n",
    "            book['rating'] = ir.find_all('a')[0].text.strip()\n",
    "            book['num_of_reviews'] = ir.find_all('a')[1].text.strip()\n",
    "        images = block.find_all('img')[0]\n",
    "        book['img_name'] = save_image(images.get('src'), str(book['rank']))\n",
    "        book_list.append(book)\n",
    "        rank +=1\n",
    "    return book_list, rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1) Using chrome webdriver to access the amazon.ca website and scrape the data from the website's page source.\n",
    "2) The get_book_list method returns the list of bestselling books which can be stored in a mongodb database.\n",
    "\"\"\"\n",
    "driver = webdriver.Chrome('E:\\\\chromedriver\\\\chromedriver.exe')\n",
    "driver.get(URL.format(1))\n",
    "book_list, rank = get_book_list(driver.page_source)\n",
    "driver.get(URL.format(2))\n",
    "book_list, rank = get_book_list(driver.page_source, book_list, rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the scraped data to mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x254ee52a9c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating the 'smd_amazon_col' collection in the 'smd_amazon_db' database and inserting the contents of the booklist into \n",
    "the 'smd_amazon_col' collection in mongodb.\n",
    "\"\"\"\n",
    "amazon_db = client['smd_amazon_db']\n",
    "amazon_col = amazon_db['smd_amazon_col']\n",
    "amazon_col.insert_many(book_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting the temporary directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deleting the images that are temporarily stored in the tempdir.\n",
    "\"\"\"\n",
    "filelist = [ f for f in os.listdir(temp_path) if f.endswith(\".jpg\") ]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(temp_path, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataprog",
   "language": "python",
   "name": "dataprog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
